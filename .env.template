# To run this project with docker compose, you need a `.env` file with the following 4 variables set.

BASE_URL="https://gpu.aet.cit.tum.de"
GITLAB_CLIENT_SECRET="" # see https://rancher.ase.cit.tum.de/dashboard/c/c-m-nhcfjg9h/explorer/secret/team-continuous-disappointment/server-secret#data gitlab-client-secret-dev
API_OPENAI="" # see https://rancher.ase.cit.tum.de/dashboard/c/c-m-nhcfjg9h/explorer/secret/team-continuous-disappointment/genai-secret#data
API_OPENWEBUI="" # see https://rancher.ase.cit.tum.de/dashboard/c/c-m-nhcfjg9h/explorer/secret/team-continuous-disappointment/genai-secret#data

# If you want to use cloud LLM models, you need to include your respective api keys (our openai key is already in rancher)

API_OPENAI="" # see https://rancher.ase.cit.tum.de/dashboard/c/c-m-nhcfjg9h/explorer/secret/team-continuous-disappointment/genai-secret#data
API_ANTHROPIC="" # your anthropic key
API_MISTRAL="" # your mistral key
API_HUGGINGFACEHUB="" # your huggingface api token