# Cloud based LLM models
# API_OPENAI="your openai key"
# API_ANTHROPIC="your anthropic key"
# API_MISTRAL="your mistral key"
# API_HUGGINGFACEHUB="your huggingface api token"

# Local Models
# API_OPENWEBUI="your openwebui key"

# You need one API key for both cloud or local LLM models.

# Base URL for calling local models
# BASE_URL="https://gpu.aet.cit.tum.de"

# For docker-compose deployment, you can use the following environment variables:
API_OPENWEBUI=""
GITLAB_CLIENT_SECRET=""
API_OPENAI=""